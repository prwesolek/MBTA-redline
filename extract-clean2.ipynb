{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For which year (2017 or 2018) do you want to run the cleaner? 2017\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def redlineisolator(filename,directory):\n",
    "    data = pd.read_csv(directory+\"/\"+filename, index_col=6, header=None) #import csv file. Column 6 is the date column.\n",
    "    data.index.rename(\"date\",inplace=True)#rename index as date\n",
    "    data=data[data[0]=='Red'] #isolate all rows pertaining to redline\n",
    "    data['ontime']=data[9]/data[10] #make a new column which gives ontime percentage\n",
    "    data=data.loc[:,[7,'ontime']] #throw away all columns except the column for the peak/off peak designation and ontime percent.\n",
    "    return data.groupby(by=7) #group data into peak and off peak frames\n",
    "\n",
    "def weathercleaner(year):\n",
    "    w_data=pd.read_csv(\"weatherdata/\"+year+\"-weather-data.csv\", index_col=['Day']) #import correct weather data csv file and set index to be 'Day' column\n",
    "    w_data=w_data.rename(columns={'High\\n\\n(°F)':'high','Low\\n\\n(°F)':'low',\n",
    "                                  'Precip.\\n\\n(inch)':'precip',\n",
    "                                  'Snow\\n\\n(inch)':'snow'})#renames columns\n",
    "    w_data.index=pd.to_datetime(w_data.index)#properly format index\n",
    "    w_data=w_data.loc[:,['high','low','precip','snow']]#eliminate all columns except temperature and precipitation columns.\n",
    "    return w_data\n",
    "\n",
    "def main_loop(directory):\n",
    "    year=directory.strip(\"-ontime-performance\") #get the year from the directory name\n",
    "    weatherdata=weathercleaner(year)#Run weather cleaner to get the weather data in the right form.\n",
    "    files=os.listdir(directory)#Open the directory with the ontime data.\n",
    "    framesp=[] #list of dataframes for peak times\n",
    "    framesop=[] # list of dataframes for offpeak times\n",
    "    for filename in files: #Run throught csv files in directory applying redlineisolator to each\n",
    "        df_p=redlineisolator(filename,directory).get_group('PEAK')\n",
    "        df_op=redlineisolator(filename,directory).get_group('OFF_PEAK')\n",
    "        framesp.append(df_p)\n",
    "        framesop.append(df_op)\n",
    "#Put peak and offpeak dataframes together into a peak frame and an off peak frame\n",
    "    peak_data=pd.concat(framesp)\n",
    "    offpeak_data=pd.concat(framesop)\n",
    "#Merge peak_data with weathedata and offpeak_data with weatherdata \n",
    "    PDW=pd.merge(peak_data, weatherdata, how='left', left_index=True, right_index=True) \n",
    "    oPDW=pd.merge(offpeak_data, weatherdata, how='left', left_index=True, right_index=True) \n",
    "#Some final cleaning\n",
    "    PDW=PDW.sort_values(by='date')\n",
    "    del PDW[7]\n",
    "    oPDW=oPDW.sort_values(by='date')\n",
    "    del oPDW[7]\n",
    "#Write to csv\n",
    "    PDW.to_csv(\"clean-files-\"+year+\"/peak-\"+year+\".csv\", sep=',', encoding='utf-8')\n",
    "    oPDW.to_csv(\"clean-files-\"+year+\"/offpeak-\"+year+\".csv\", sep=',', encoding='utf-8')\n",
    "    \n",
    "if __name__ == '__main__': \n",
    "    year=input( \"For which year (2017 or 2018) do you want to run the cleaner? \") #ask for year input\n",
    "    directory=year+\"-ontime-performance\"\n",
    "    main_loop(directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
